{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /workspaces/UQ_Early_prediction_MI_BCI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n",
      "Choosing from all possible events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
      "\n",
      "\n",
      "threshold: 0.000000 / 1, patience: 1 / 20\n",
      "\n",
      "\n",
      "Person 1\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "Adding metadata with 3 columns\n",
      "576 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/paradigms/base.py:354: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  X = mne.concatenate_epochs(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 3.3e-05 (2.2e-16 eps * 22 dim * 6.8e+09  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 143\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m / 1, patience: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m / 20\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (threshold,  patience))\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 143\u001b[0m accuracy, mean_prediction_time, epochs, labels \u001b[38;5;241m=\u001b[39m \u001b[43mrun_expanding_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfidence_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_window_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexpansion_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msfreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m accuracy_row\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[1;32m    145\u001b[0m prediction_time_row\u001b[38;5;241m.\u001b[39mappend(mean_prediction_time)\n",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m, in \u001b[0;36mrun_expanding_classification\u001b[0;34m(subjects, threshold, patience, confidence_type, initial_window_length, expansion_rate, sfreq)\u001b[0m\n\u001b[1;32m     59\u001b[0m current_cv \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m labels[train_idx], labels[test_idx]\n\u001b[0;32m---> 61\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mcsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_data_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m lda\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     63\u001b[0m w_start \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, epochs_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m initial_window_length, expansion_rate) \n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/decoding/csp.py:252\u001b[0m, in \u001b[0;36mCSP.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;129m@copy_doc\u001b[39m(TransformerMixin\u001b[38;5;241m.\u001b[39mfit_transform)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/decoding/mixin.py:33\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/decoding/csp.py:190\u001b[0m, in \u001b[0;36mCSP.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malternate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent_order=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malternate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires two \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses, but data contains \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m classes; use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent_order=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutual_info\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_classes)\n\u001b[1;32m    188\u001b[0m     )\n\u001b[0;32m--> 190\u001b[0m covs, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_covariance_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m eigen_vectors, eigen_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompose_covs(covs, sample_weights)\n\u001b[1;32m    192\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_order_components(\n\u001b[1;32m    193\u001b[0m     covs, sample_weights, eigen_vectors, eigen_values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_order\n\u001b[1;32m    194\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/decoding/csp.py:527\u001b[0m, in \u001b[0;36mCSP._compute_covariance_matrices\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    525\u001b[0m sample_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m this_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classes:\n\u001b[0;32m--> 527\u001b[0m     cov, weight \u001b[38;5;241m=\u001b[39m \u001b[43mcov_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthis_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_trace:\n\u001b[1;32m    530\u001b[0m         cov \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrace(cov)\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/decoding/csp.py:543\u001b[0m, in \u001b[0;36mCSP._concat_cov\u001b[0;34m(self, x_class)\u001b[0m\n\u001b[1;32m    541\u001b[0m x_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(x_class, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    542\u001b[0m x_class \u001b[38;5;241m=\u001b[39m x_class\u001b[38;5;241m.\u001b[39mreshape(n_channels, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 543\u001b[0m cov \u001b[38;5;241m=\u001b[39m \u001b[43m_regularized_covariance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov_method_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m weight \u001b[38;5;241m=\u001b[39m x_class\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cov, weight\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/cov.py:2112\u001b[0m, in \u001b[0;36m_regularized_covariance\u001b[0;34m(data, reg, method_params, info, rank)\u001b[0m\n\u001b[1;32m   2110\u001b[0m picks_list \u001b[38;5;241m=\u001b[39m _picks_by_type(info)\n\u001b[1;32m   2111\u001b[0m scalings \u001b[38;5;241m=\u001b[39m _handle_default(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalings_cov_rank\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2112\u001b[0m cov \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_covariance_auto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_early\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpicks_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpicks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[reg][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cov\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/cov.py:1251\u001b[0m, in \u001b[0;36m_compute_covariance_auto\u001b[0;34m(data, method, info, method_params, cv, scalings, n_jobs, stop_early, picks_list, rank)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;66;03m# rescale to improve numerical stability\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m orig_rank \u001b[38;5;241m=\u001b[39m rank\n\u001b[0;32m-> 1251\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_rank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRawArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_verbose_safe_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _scaled_array(data\u001b[38;5;241m.\u001b[39mT, picks_list, scalings):\n\u001b[1;32m   1258\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(data\u001b[38;5;241m.\u001b[39mT, data)\n",
      "File \u001b[0;32m<decorator-gen-90>:12\u001b[0m, in \u001b[0;36mcompute_rank\u001b[0;34m(inst, rank, scalings, info, tol, proj, tol_kind, on_rank_mismatch, verbose)\u001b[0m\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/rank.py:449\u001b[0m, in \u001b[0;36mcompute_rank\u001b[0;34m(inst, rank, scalings, info, tol, proj, tol_kind, on_rank_mismatch, verbose)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proj:\n\u001b[1;32m    448\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(proj_op, data)\n\u001b[0;32m--> 449\u001b[0m     this_rank \u001b[38;5;241m=\u001b[39m \u001b[43m_estimate_rank_meeg_signals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpick_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimple_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol_kind\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, Covariance)\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/rank.py:182\u001b[0m, in \u001b[0;36m_estimate_rank_meeg_signals\u001b[0;34m(data, info, scalings, tol, return_singular, tol_kind)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve got fewer samples than channels, your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank estimate might be inaccurate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _scaled_array(data, picks_list, scalings):\n\u001b[0;32m--> 182\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_rank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_singular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol_kind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol_kind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m rank \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[1;32m    190\u001b[0m ch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m + \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mpicks_list))[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m<decorator-gen-87>:12\u001b[0m, in \u001b[0;36mestimate_rank\u001b[0;34m(data, tol, return_singular, norm, tol_kind, verbose)\u001b[0m\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/rank.py:71\u001b[0m, in \u001b[0;36mestimate_rank\u001b[0;34m(data, tol, return_singular, norm, tol_kind, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m     norms \u001b[38;5;241m=\u001b[39m _compute_row_norms(data)\n\u001b[1;32m     70\u001b[0m     data \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m norms[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m---> 71\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvdvals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m rank \u001b[38;5;241m=\u001b[39m _estimate_rank_from_s(s, tol, tol_kind)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_singular \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py:241\u001b[0m, in \u001b[0;36msvdvals\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    239\u001b[0m a \u001b[38;5;241m=\u001b[39m _asarray_validated(a, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py:141\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    137\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    138\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from mne.decoding import CSP\n",
    "\n",
    "current_directory = os.path.abspath('')\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(current_directory, '..', '..', '..', '..'))\n",
    "\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"ROOT:\", project_root)\n",
    "from Early_predict_UQ.data.make_dataset import make_data\n",
    "\n",
    "\n",
    "\n",
    "def early_pred(probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold):\n",
    "    probabilities = probabilities.flatten()\n",
    "    sorted_probs = sorted(probabilities, reverse=True)\n",
    "    if confidence_type == 'highest_prob':\n",
    "        confidence = sorted_probs[0]\n",
    "        print(\"confidence:\", confidence)\n",
    "    else:\n",
    "        confidence = 1 - (1 / (1 + (sorted_probs[0] + (sorted_probs[0] - sorted_probs[1]))))\n",
    "        print(\"confidence:\", confidence)\n",
    "    if confidence > threshold and not predict:\n",
    "        sorted_probs[0]\n",
    "        numTimesBelowThreshold += 1\n",
    "        if numTimesBelowThreshold == patience:\n",
    "            predict = True\n",
    "    return predict, confidence, numTimesBelowThreshold\n",
    "\n",
    "def run_expanding_classification(subjects, threshold, patience, confidence_type, initial_window_length, expansion_rate, sfreq):\n",
    "    scores_across_subjects = []\n",
    "    prediction_time_across_subjects = []\n",
    "    current_person = 0\n",
    "    for person in subjects:\n",
    "        current_person += 1\n",
    "        print(\"Person %d\" % (person))\n",
    "        subject= [person]\n",
    "        epochs, labels = make_data(subject)\n",
    "        epochs_train = epochs.copy()\n",
    "        labels = epochs.events[:, -1] - 4\n",
    "        epochs_data = epochs.get_data(copy=False)\n",
    "        epochs_data_train = epochs_train.get_data(copy=False)\n",
    "\n",
    "        cv = ShuffleSplit(2, test_size=0.2, random_state=42)\n",
    "        cv_split = cv.split(epochs_data_train)\n",
    "        scores_cv_splits = []\n",
    "        predict_time_cv_splits = []\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
    "        current_cv = 0 \n",
    "        for train_idx, test_idx in cv_split:\n",
    "            current_cv += 1\n",
    "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "            X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "            lda.fit(X_train, y_train)\n",
    "            w_start = np.arange(0, epochs_data.shape[2] - initial_window_length, expansion_rate) \n",
    "            scores_across_epochs = []\n",
    "            predict_time_across_epochs = []\n",
    "\n",
    "            for epoch_idx in range(len(test_idx)):\n",
    "                predict = False\n",
    "                numTimesBelowThreshold = 0\n",
    "                for n, window_start in enumerate(w_start):\n",
    "                    window_length = initial_window_length + n * expansion_rate\n",
    "                    X_test_window = csp.transform(epochs_data_train[test_idx][:, :,  window_start:(window_start + window_length)])\n",
    "                    X_test_epoch_window = X_test_window[epoch_idx]\n",
    "                    probabilities = lda.predict_proba([X_test_epoch_window])\n",
    "                    probabilities = np.array(probabilities)\n",
    "                    probabilities = probabilities.flatten()\n",
    "                    predict, confidence, numTimesBelowThreshold = early_pred(\n",
    "                        probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold\n",
    "                    )\n",
    "                    if predict:\n",
    "                        #IF WE DIDNT PREDICT EARLY, MAYBE PREDICT ON THE WHOLE EPOCH?\n",
    "                        predict_time = n\n",
    "                        score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                        break\n",
    "                else:\n",
    "                    predict_time = n\n",
    "                    score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                predict_time = (predict_time + initial_window_length / 2.0) / sfreq + epochs.tmin\n",
    "                scores_across_epochs.append(score)\n",
    "                predict_time_across_epochs.append(predict_time)\n",
    "\n",
    "            if current_cv == 1:\n",
    "                scores_cv_splits = np.array(scores_across_epochs)\n",
    "                predict_time_cv_splits = np.array(predict_time_across_epochs)\n",
    "            else:\n",
    "                scores_cv_splits = np.vstack((scores_cv_splits,np.array(scores_across_epochs)))\n",
    "                predict_time_cv_splits = np.vstack((predict_time_cv_splits,np.array(predict_time_across_epochs)))\n",
    "\n",
    "        mean_scores_across_cv = np.mean(scores_cv_splits, axis=0)\n",
    "        mean_predict_time_across_cv = np.mean(predict_time_cv_splits, axis=0)\n",
    "        if current_person == 1:\n",
    "            scores_across_subjects  = np.array(mean_scores_across_cv)\n",
    "            prediction_time_across_subjects = np.array(mean_predict_time_across_cv)\n",
    "        else:\n",
    "            scores_across_subjects = np.vstack((scores_across_subjects,np.array(mean_scores_across_cv)))\n",
    "            prediction_time_across_subjects = np.vstack((predict_time_cv_splits,np.array(mean_predict_time_across_cv)))\n",
    "\n",
    "        mean_scores_across_subjects = np.mean(scores_across_subjects, axis=0)\n",
    "        accuracy = np.mean(mean_scores_across_subjects)\n",
    "\n",
    "        mean_prediction_time_across_subjects = np.mean(prediction_time_across_subjects, axis=0)\n",
    "        mean_prediction_time = np.mean(mean_prediction_time_across_subjects)\n",
    "    return accuracy, mean_prediction_time, epochs, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #threshold = 0.6  # values - {0,1}\n",
    "    #patience = 4 # values - {1,36}\n",
    "    subjects = [1, 2, 3, 4, 5, 6, 7, 8, 9]  # 9 subjects\n",
    "\n",
    "    confidence_type = 'cost_func' # 'highest_prob' or the cost function. # hyperparameter - maybe compare in different files\n",
    "    sfreq = 250      \n",
    "    initial_window_length = int(sfreq * 0.9)  \n",
    "    expansion_rate = int(sfreq * 0.3)   \n",
    "\n",
    "    patience_values = np.arange(1, 13, 3) \n",
    "    threshold_values = np.arange(0, 1, 0.2)\n",
    "\n",
    "    #csp components #hyperparameter\n",
    "    #cross validation #hyperparmater\n",
    "    accuracy_array = []\n",
    "    prediction_time_array = []\n",
    "\n",
    "    #MIGHT BE TOO INTENSIVE FOR THE KERNEL, maybe tune the other hyperparameters first, then with the best values, loop over patience, and trehsold\n",
    "    # over threshold values\n",
    "    for threshold in threshold_values:\n",
    "        accuracy_row = []\n",
    "        prediction_time_row = []\n",
    "        # over patience values\n",
    "        for patience in patience_values:\n",
    "            print(\"\\n\")\n",
    "            print(\"threshold: %f / 1, patience: %d / 20\" % (threshold,  patience))\n",
    "            print(\"\\n\")\n",
    "            accuracy, mean_prediction_time, epochs, labels = run_expanding_classification(subjects, threshold, patience, confidence_type, initial_window_length,expansion_rate, sfreq)\n",
    "            accuracy_row.append(accuracy)\n",
    "            prediction_time_row.append(mean_prediction_time)\n",
    "        accuracy_array.append(accuracy_row)\n",
    "        prediction_time_array.append(prediction_time_row)\n",
    "\n",
    "    accuracy_array = np.array(accuracy_array)\n",
    "    prediction_time_array = np.array(prediction_time_array)\n",
    "\n",
    "    print(\"accuracy_array: \", accuracy_array)\n",
    "    print(\"prediction_time_array: \",  prediction_time_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
