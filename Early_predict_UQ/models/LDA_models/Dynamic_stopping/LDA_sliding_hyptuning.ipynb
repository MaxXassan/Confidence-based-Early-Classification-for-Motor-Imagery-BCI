{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hyperparameter tuning - highest_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from mne.decoding import CSP\n",
    "\n",
    "current_directory = os.path.abspath('')\n",
    "project_root = os.path.abspath(os.path.join(current_directory, '..', '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "print(\"ROOT:\", project_root)\n",
    "from Early_predict_UQ.data.make_dataset import make_data\n",
    "\n",
    "def early_pred(probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold):\n",
    "    probabilities = probabilities.flatten()\n",
    "    sorted_probs = sorted(probabilities, reverse=True)\n",
    "    if confidence_type == 'highest_prob':\n",
    "        confidence = sorted_probs[0]\n",
    "    else:\n",
    "        confidence = 1 - (1 / (1 + (sorted_probs[0] + (sorted_probs[0] - sorted_probs[1]))))\n",
    "    if confidence > threshold and not predict:\n",
    "        numTimesBelowThreshold += 1\n",
    "        if numTimesBelowThreshold == patience:\n",
    "            predict = True\n",
    "    return predict, confidence, numTimesBelowThreshold\n",
    "\n",
    "def run_sliding_classification(subjects, threshold, patience, confidence_type, w_length, w_step, sfreq, n_components):\n",
    "    scores_across_subjects = []\n",
    "    prediction_time_across_subjects = []\n",
    "    for person in subjects:\n",
    "        print(\"Processing Person %d\" % (person))  # Print statement to track progress\n",
    "        subject= [person]\n",
    "        epochs, labels = make_data(subject)\n",
    "        epochs_train = epochs.copy()\n",
    "        labels = epochs.events[:, -1] - 4\n",
    "        epochs_data = epochs.get_data(copy=False)\n",
    "        epochs_data_train = epochs_train.get_data(copy=False)\n",
    "\n",
    "        cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "        cv_split = cv.split(epochs_data_train)\n",
    "        scores_cv_splits = []\n",
    "        predict_time_cv_splits = []\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        csp = CSP(n_components=n_components, reg=None, log=True, norm_trace=False)\n",
    "        for train_idx, test_idx in cv_split:\n",
    "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "            X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "            lda.fit(X_train, y_train)\n",
    "            w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "            scores_across_epochs = []\n",
    "            predict_time_across_epochs = []\n",
    "\n",
    "            for epoch_idx in range(len(test_idx)):\n",
    "                predict = False\n",
    "                numTimesBelowThreshold = 0\n",
    "                for n in w_start:\n",
    "                    X_test_window = csp.transform(epochs_data_train[test_idx][:, :, n:(n + w_length)])\n",
    "                    X_test_epoch_window = X_test_window[epoch_idx]\n",
    "                    probabilities = lda.predict_proba([X_test_epoch_window])\n",
    "                    probabilities = np.array(probabilities)\n",
    "                    probabilities = probabilities.flatten()\n",
    "                    predict, confidence, numTimesBelowThreshold = early_pred(\n",
    "                        probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold\n",
    "                    )\n",
    "                    if predict:\n",
    "                        predict_time = n\n",
    "                        score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                        break\n",
    "                else:\n",
    "                    predict_time = n\n",
    "                    score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                predict_time = (predict_time + w_length / 2.0) / sfreq + epochs.tmin\n",
    "                scores_across_epochs.append(score)\n",
    "                predict_time_across_epochs.append(predict_time)\n",
    "\n",
    "            scores_cv_splits.append(np.mean(scores_across_epochs))\n",
    "            predict_time_cv_splits.append(np.mean(predict_time_across_epochs))\n",
    "\n",
    "        mean_scores_across_cv = np.mean(scores_cv_splits)\n",
    "        mean_predict_time_across_cv = np.mean(predict_time_cv_splits)\n",
    "\n",
    "        scores_across_subjects.append(mean_scores_across_cv)\n",
    "        prediction_time_across_subjects.append(mean_predict_time_across_cv)\n",
    "\n",
    "    accuracy = np.mean(scores_across_subjects)\n",
    "    mean_prediction_time = np.mean(prediction_time_across_subjects)\n",
    "\n",
    "    return accuracy, mean_prediction_time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    threshold = 0.4  # values - {0,1}\n",
    "    patience = 4  # values - {1,36}\n",
    "    subjects = [1, 2, 3, 4, 5, 6, 7, 8, 9]  # 9 subjects\n",
    "    confidence_type = 'highest_prob'  # 'highest_prob' or the cost function. # hyperparameter - maybe compare in different files\n",
    "    sfreq = 250\n",
    "    w_length = int(sfreq * 0.5)\n",
    "    w_step = int(sfreq * 0.5)\n",
    "\n",
    "    # Define hyperparameter values\n",
    "    n_components_values = [2, 4, 6, 8, 10]\n",
    "    w_length_values = [int(sfreq * 0.1), int(sfreq * 0.5), int(sfreq * 1)]\n",
    "    w_step_values = [int(sfreq * 0.1), int(sfreq * 0.5), int(sfreq * 1)]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n_components in n_components_values:\n",
    "        for w_length in w_length_values:\n",
    "            for w_step in w_step_values:\n",
    "                print(\"Evaluating: n_components={}, w_length={}, w_step={}\".format(n_components, w_length, w_step))  # Print statement to track progress\n",
    "                accuracy, mean_prediction_time = run_sliding_classification(subjects, threshold, patience, confidence_type, w_length, w_step, sfreq, n_components)\n",
    "                results.append((n_components, w_length, w_step, accuracy, mean_prediction_time))\n",
    "\n",
    "    # Print results\n",
    "    for result in results:\n",
    "        print(\"n_components: {}, w_length: {}, w_step: {}, accuracy: {}, mean_prediction_time: {}\".format(*result))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "To do - dynamic stop:\n",
    "- sliding\n",
    "    - make the for loops work and contain and provide the mean predict time and score correctly X\n",
    "    - then advance to for all subjects X\n",
    "    - modularize\n",
    "    - the start the hyperparameter tuning to maximize classification accuracy, and minimize predict_time \n",
    "    - then loop across all threshold values \n",
    "    - make it take into account all the subjects\n",
    "    - make it work using svm\n",
    "    - provide the plots for all the subjects for all subjects for each condition, let it just save the plots to a folder automatically (potentially also the values to make plots somewhere else)\n",
    "    - nb: watch the memory and time usage for codespaces\n",
    "- expanding:\n",
    "    - make a new file, adjust to use expanding window\n",
    "    - save its plots into another folder automaically\n",
    "            \n",
    "To do - static:\n",
    "- make a new file and adjust the dynamic to just use a specific predict times using the cost function\n",
    "- save the plots\n",
    "\n",
    "to do - whole:\n",
    "- already did that \n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hyperparameter tuning - cost func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from mne.decoding import CSP\n",
    "\n",
    "current_directory = os.path.abspath('')\n",
    "project_root = os.path.abspath(os.path.join(current_directory, '..', '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "print(\"ROOT:\", project_root)\n",
    "from Early_predict_UQ.data.make_dataset import make_data\n",
    "\n",
    "def early_pred(probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold):\n",
    "    probabilities = probabilities.flatten()\n",
    "    sorted_probs = sorted(probabilities, reverse=True)\n",
    "    if confidence_type == 'highest_prob':\n",
    "        confidence = sorted_probs[0]\n",
    "    else:\n",
    "        confidence = 1 - (1 / (1 + (sorted_probs[0] + (sorted_probs[0] - sorted_probs[1]))))\n",
    "    if confidence > threshold and not predict:\n",
    "        numTimesBelowThreshold += 1\n",
    "        if numTimesBelowThreshold == patience:\n",
    "            predict = True\n",
    "    return predict, confidence, numTimesBelowThreshold\n",
    "\n",
    "def run_sliding_classification(subjects, threshold, patience, confidence_type, w_length, w_step, sfreq, n_components):\n",
    "    scores_across_subjects = []\n",
    "    prediction_time_across_subjects = []\n",
    "    for person in subjects:\n",
    "        print(\"Processing Person %d\" % (person))  # Print statement to track progress\n",
    "        subject= [person]\n",
    "        epochs, labels = make_data(subject)\n",
    "        epochs_train = epochs.copy()\n",
    "        labels = epochs.events[:, -1] - 4\n",
    "        epochs_data = epochs.get_data(copy=False)\n",
    "        epochs_data_train = epochs_train.get_data(copy=False)\n",
    "\n",
    "        cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "        cv_split = cv.split(epochs_data_train)\n",
    "        scores_cv_splits = []\n",
    "        predict_time_cv_splits = []\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        csp = CSP(n_components=n_components, reg=None, log=True, norm_trace=False)\n",
    "        for train_idx, test_idx in cv_split:\n",
    "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "            X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "            lda.fit(X_train, y_train)\n",
    "            w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "            scores_across_epochs = []\n",
    "            predict_time_across_epochs = []\n",
    "\n",
    "            for epoch_idx in range(len(test_idx)):\n",
    "                predict = False\n",
    "                numTimesBelowThreshold = 0\n",
    "                for n in w_start:\n",
    "                    X_test_window = csp.transform(epochs_data_train[test_idx][:, :, n:(n + w_length)])\n",
    "                    X_test_epoch_window = X_test_window[epoch_idx]\n",
    "                    probabilities = lda.predict_proba([X_test_epoch_window])\n",
    "                    probabilities = np.array(probabilities)\n",
    "                    probabilities = probabilities.flatten()\n",
    "                    predict, confidence, numTimesBelowThreshold = early_pred(\n",
    "                        probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold\n",
    "                    )\n",
    "                    if predict:\n",
    "                        predict_time = n\n",
    "                        score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                        break\n",
    "                else:\n",
    "                    predict_time = n\n",
    "                    score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                predict_time = (predict_time + w_length / 2.0) / sfreq + epochs.tmin\n",
    "                scores_across_epochs.append(score)\n",
    "                predict_time_across_epochs.append(predict_time)\n",
    "\n",
    "            scores_cv_splits.append(np.mean(scores_across_epochs))\n",
    "            predict_time_cv_splits.append(np.mean(predict_time_across_epochs))\n",
    "\n",
    "        mean_scores_across_cv = np.mean(scores_cv_splits)\n",
    "        mean_predict_time_across_cv = np.mean(predict_time_cv_splits)\n",
    "\n",
    "        scores_across_subjects.append(mean_scores_across_cv)\n",
    "        prediction_time_across_subjects.append(mean_predict_time_across_cv)\n",
    "\n",
    "    accuracy = np.mean(scores_across_subjects)\n",
    "    mean_prediction_time = np.mean(prediction_time_across_subjects)\n",
    "\n",
    "    return accuracy, mean_prediction_time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    threshold = 0.4  # values - {0,1}\n",
    "    patience = 4  # values - {1,36}\n",
    "    subjects = [1, 2, 3, 4, 5, 6, 7, 8, 9]  # 9 subjects\n",
    "    confidence_type = 'cost'  # 'highest_prob' or the cost function. # hyperparameter - maybe compare in different files\n",
    "    sfreq = 250\n",
    "    w_length = int(sfreq * 0.5)\n",
    "    w_step = int(sfreq * 0.5)\n",
    "\n",
    "    # Define hyperparameter values\n",
    "    n_components_values = [2, 4, 6, 8, 10]\n",
    "    w_length_values = [int(sfreq * 0.1), int(sfreq * 0.5), int(sfreq * 1)]\n",
    "    w_step_values = [int(sfreq * 0.1), int(sfreq * 0.5), int(sfreq * 1)]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n_components in n_components_values:\n",
    "        for w_length in w_length_values:\n",
    "            for w_step in w_step_values:\n",
    "                print(\"Evaluating: n_components={}, w_length={}, w_step={}\".format(n_components, w_length, w_step))  # Print statement to track progress\n",
    "                accuracy, mean_prediction_time = run_sliding_classification(subjects, threshold, patience, confidence_type, w_length, w_step, sfreq, n_components)\n",
    "                results.append((n_components, w_length, w_step, accuracy, mean_prediction_time))\n",
    "\n",
    "    # Print results\n",
    "    for result in results:\n",
    "        print(\"n_components: {}, w_length: {}, w_step: {}, accuracy: {}, mean_prediction_time: {}\".format(*result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
