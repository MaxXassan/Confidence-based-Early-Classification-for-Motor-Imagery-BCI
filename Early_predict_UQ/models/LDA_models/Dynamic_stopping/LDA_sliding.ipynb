{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /workspaces/UQ_Early_prediction_MI_BCI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n",
      "Choosing from all possible events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m subject\u001b[38;5;241m=\u001b[39m [person] \u001b[38;5;66;03m# Choosing the subject \u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Preprocessed epochs\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m epochs, labels \u001b[38;5;241m=\u001b[39m \u001b[43mmake_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Asserting the epochs and labels (last row of the events matrix) to be used for the classification\u001b[39;00m\n\u001b[1;32m     62\u001b[0m epochs_train \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/Early_predict_UQ/data/make_dataset.py:21\u001b[0m, in \u001b[0;36mmake_data\u001b[0;34m(subject_list)\u001b[0m\n\u001b[1;32m     19\u001b[0m dataset \u001b[38;5;241m=\u001b[39m BNCI2014_001()\n\u001b[1;32m     20\u001b[0m paradigm \u001b[38;5;241m=\u001b[39m MotorImagery(fmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, fmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m) \u001b[38;5;66;03m# Bandpass filter between to enhance mu and beta frequencies\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m epochs, labels, _ \u001b[38;5;241m=\u001b[39m \u001b[43mparadigm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubject_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epochs, labels\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/paradigms/base.py:278\u001b[0m, in \u001b[0;36mBaseProcessing.get_data\u001b[0;34m(self, dataset, subjects, return_epochs, return_raws, cache_config, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    273\u001b[0m process_pipelines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_process_pipelines(\n\u001b[1;32m    274\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[1;32m    275\u001b[0m )\n\u001b[1;32m    276\u001b[0m labels_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[0;32m--> 278\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess_pipelines\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    287\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    288\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/paradigms/base.py:279\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m process_pipelines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_process_pipelines(\n\u001b[1;32m    274\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[1;32m    275\u001b[0m )\n\u001b[1;32m    276\u001b[0m labels_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[1;32m    278\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 279\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m process_pipeline \u001b[38;5;129;01min\u001b[39;00m process_pipelines\n\u001b[1;32m    285\u001b[0m ]\n\u001b[1;32m    287\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    288\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/datasets/base.py:342\u001b[0m, in \u001b[0;36mBaseDataset.get_data\u001b[0;34m(self, subjects, cache_config, process_pipeline)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject_list:\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid subject \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subject))\n\u001b[0;32m--> 342\u001b[0m     data[subject] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_single_subject_data_using_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m check_subject_names(data)\n\u001b[1;32m    348\u001b[0m check_session_names(data)\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/datasets/base.py:466\u001b[0m, in \u001b[0;36mBaseDataset._get_single_subject_data_using_cache\u001b[0;34m(self, subject, cache_config, process_pipeline)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Apply remaining steps and save:\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_idx, (step_type, process_pipeline) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(remaining_steps):\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# apply one step:\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     sessions_data \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msessions_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# save:\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    476\u001b[0m         (\n\u001b[1;32m    477\u001b[0m             cache_config\u001b[38;5;241m.\u001b[39msave_raw\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (cache_config\u001b[38;5;241m.\u001b[39msave_array \u001b[38;5;129;01mand\u001b[39;00m step_type \u001b[38;5;129;01mis\u001b[39;00m StepType\u001b[38;5;241m.\u001b[39mARRAY)\n\u001b[1;32m    486\u001b[0m     ):\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/datasets/base.py:467\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Apply remaining steps and save:\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_idx, (step_type, process_pipeline) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(remaining_steps):\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# apply one step:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     sessions_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 467\u001b[0m         session: \u001b[43m{\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m session, runs \u001b[38;5;129;01min\u001b[39;00m sessions_data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    472\u001b[0m     }\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# save:\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    476\u001b[0m         (\n\u001b[1;32m    477\u001b[0m             cache_config\u001b[38;5;241m.\u001b[39msave_raw\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (cache_config\u001b[38;5;241m.\u001b[39msave_array \u001b[38;5;129;01mand\u001b[39;00m step_type \u001b[38;5;129;01mis\u001b[39;00m StepType\u001b[38;5;241m.\u001b[39mARRAY)\n\u001b[1;32m    486\u001b[0m     ):\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/datasets/base.py:468\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Apply remaining steps and save:\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_idx, (step_type, process_pipeline) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(remaining_steps):\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# apply one step:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     sessions_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    467\u001b[0m         session: {\n\u001b[0;32m--> 468\u001b[0m             run: \u001b[43mapply_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m run, raw \u001b[38;5;129;01min\u001b[39;00m runs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    470\u001b[0m         }\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m session, runs \u001b[38;5;129;01min\u001b[39;00m sessions_data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    472\u001b[0m     }\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# save:\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    476\u001b[0m         (\n\u001b[1;32m    477\u001b[0m             cache_config\u001b[38;5;241m.\u001b[39msave_raw\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (cache_config\u001b[38;5;241m.\u001b[39msave_array \u001b[38;5;129;01mand\u001b[39;00m step_type \u001b[38;5;129;01mis\u001b[39;00m StepType\u001b[38;5;241m.\u001b[39mARRAY)\n\u001b[1;32m    486\u001b[0m     ):\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/moabb/datasets/base.py:101\u001b[0m, in \u001b[0;36mapply_step\u001b[0;34m(pipeline, obj)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# no events received by RawToEpochs:\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo events found\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:267\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    266\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 267\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m output_config \u001b[38;5;241m=\u001b[39m _get_output_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# check the consistency between the column provided by `transform` and\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# the the column names provided by `get_feature_names_out`.\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:394\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     func \u001b[38;5;241m=\u001b[39m _identity\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/io/base.py:1128\u001b[0m, in \u001b[0;36mBaseRaw.filter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;129m@copy_doc\u001b[39m(FilterMixin\u001b[38;5;241m.\u001b[39mfilter)\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1127\u001b[0m ):  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m-> 1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43miir_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miir_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_design\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_design\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_by_annotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_by_annotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-83>:10\u001b[0m, in \u001b[0;36mfilter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/filter.py:2610\u001b[0m, in \u001b[0;36mFilterMixin.filter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m si, (start, stop) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(onsets, ends)):\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;66;03m# Only output filter params once (for info level), and only warn\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;66;03m# once about the length criterion (longest segment is too short)\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m     use_verbose \u001b[38;5;241m=\u001b[39m verbose \u001b[38;5;28;01mif\u001b[39;00m si \u001b[38;5;241m==\u001b[39m max_idx \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2610\u001b[0m     \u001b[43mfilter_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msfreq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m        \u001b[49m\u001b[43miir_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_design\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_design\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;66;03m# update info if filter is applied to all data channels,\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m \u001b[38;5;66;03m# and it's not a band-stop filter\u001b[39;00m\n\u001b[1;32m   2631\u001b[0m _filt_update_info(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo, update_info, l_freq, h_freq)\n",
      "File \u001b[0;32m<decorator-gen-78>:10\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/filter.py:1114\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     data \u001b[38;5;241m=\u001b[39m _overlap_add_filter(data, filt, \u001b[38;5;28;01mNone\u001b[39;00m, phase, picks, n_jobs, copy, pad)\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1114\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_iir_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/mne/filter.py:651\u001b[0m, in \u001b[0;36m_iir_filter\u001b[0;34m(x, iir_params, picks, n_jobs, copy, phase)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m picks:\n\u001b[0;32m--> 651\u001b[0m         x[p] \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    653\u001b[0m     data_new \u001b[38;5;241m=\u001b[39m parallel(p_fun(x\u001b[38;5;241m=\u001b[39mx[p]) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m picks)\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/scipy/signal/_signaltools.py:4463\u001b[0m, in \u001b[0;36msosfiltfilt\u001b[0;34m(sos, x, axis, padtype, padlen)\u001b[0m\n\u001b[1;32m   4461\u001b[0m (y, zf) \u001b[38;5;241m=\u001b[39m sosfilt(sos, ext, axis\u001b[38;5;241m=\u001b[39maxis, zi\u001b[38;5;241m=\u001b[39mzi \u001b[38;5;241m*\u001b[39m x_0)\n\u001b[1;32m   4462\u001b[0m y_0 \u001b[38;5;241m=\u001b[39m axis_slice(y, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m-> 4463\u001b[0m (y, zf) \u001b[38;5;241m=\u001b[39m \u001b[43msosfilt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_reverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4464\u001b[0m y \u001b[38;5;241m=\u001b[39m axis_reverse(y, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   4465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/workspaces/UQ_Early_prediction_MI_BCI/.conda/lib/python3.11/site-packages/scipy/signal/_signaltools.py:4345\u001b[0m, in \u001b[0;36msosfilt\u001b[0;34m(sos, x, axis, zi)\u001b[0m\n\u001b[1;32m   4343\u001b[0m zi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(np\u001b[38;5;241m.\u001b[39mreshape(zi, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_sections, \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m   4344\u001b[0m sos \u001b[38;5;241m=\u001b[39m sos\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 4345\u001b[0m \u001b[43m_sosfilt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4346\u001b[0m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m x_shape\n\u001b[1;32m   4347\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(x, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from mne.decoding import CSP\n",
    "\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = os.path.abspath('')\n",
    "\n",
    "# Move two directories up\n",
    "project_root = os.path.abspath(os.path.join(current_directory,  '..', '..', '..', '..'))\n",
    "\n",
    "# Append the project root to sys.path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"ROOT:\", project_root)\n",
    "from Early_predict_UQ.data.make_dataset import make_data\n",
    "from Early_predict_UQ.data.plots import plot_accuracy_over_time_and_epochs, plot_confidence_over_time_and_epochs #, plot_cost_over_time_and_epochs\n",
    "\n",
    "def early_pred(probabilities, predict, numTimesBelowThreshold, patience, confidence_type):\n",
    "                probabilities = probabilities.flatten()\n",
    "                sorted_probs = sorted(probabilities, reverse=True)\n",
    "                #cost1 = 1/(1+(sorted_probs[0] - sorted_probs[1]))\n",
    "                if confidence_type == 'highest_prob':\n",
    "                    confidence = sorted_probs[0]\n",
    "                else:\n",
    "                    # confidence_type is 'two_highest_difference'\n",
    "                    #Based on the stopping rule described in DOI: 10.1109/TNNLS.2017.2764939\n",
    "                    confidence = 1/(1+(sorted_probs[0] + (sorted_probs[0] - sorted_probs[1])))\n",
    "                if confidence > threshold and predict == False:\n",
    "                    #print(\"Confidence reached\")\n",
    "                    numTimesBelowThreshold +=1\n",
    "                    #print(\"numTimesBelowThreshold: \",numTimesBelowThreshold)\n",
    "                    if numTimesBelowThreshold == patience:\n",
    "                        predict = True\n",
    "                return predict, confidence, numTimesBelowThreshold\n",
    "\n",
    "# Setting hyper-parameters\n",
    "threshold = 0.5 # need to be a list with values between 0 and 1 to loop over\n",
    "patience = 4 # numTimesBelowThreshold - potential hyperparameter\n",
    "current_person = 0\n",
    "subjects = [1,2,3,4,5,6,7,8,9]  #all sucbjects\n",
    "scores_across_subjects = [] \n",
    "prediction_time_across_subjects = []\n",
    "confidence_across_subjects = []\n",
    "for person in subjects:\n",
    "    current_person += 1\n",
    "    subject= [person] # Choosing the subject \n",
    "\n",
    "    # Preprocessed epochs\n",
    "    epochs, labels = make_data(subject)\n",
    "\n",
    "    # Asserting the epochs and labels (last row of the events matrix) to be used for the classification\n",
    "    epochs_train = epochs.copy()\n",
    "    labels = epochs.events[:, -1] - 4\n",
    "\n",
    "    currentcv = 0\n",
    "    current_epoch = 0\n",
    "    current_window = 0\n",
    "    # Cross validation \n",
    "    ## (Might need to do cross session - session 1 as train, and session 2 as test. See dataset_structure.ipynb)\n",
    "    scores = []\n",
    "    epochs_data = epochs.get_data(copy=False)\n",
    "    epochs_data_train = epochs_train.get_data(copy=False)\n",
    "    \n",
    "    #Cross validation  (CV)\n",
    "    cv = ShuffleSplit(10, test_size=0.2, random_state=42) #Potential hyperparameter.\n",
    "    cv_split = cv.split(epochs_data_train)\n",
    "\n",
    "    # Linear discriminant analysis (LDA) and Common Spatial Pattern (CSP)\n",
    "    lda = LinearDiscriminantAnalysis() # classifier\n",
    "    csp = CSP(n_components=5, reg=None, log=True, norm_trace=False) # why 4 components or 5 ? Potential hyperparameter.\n",
    "\n",
    "    confidence_type = ['highest_prob', 'two_highest_difference']\n",
    "    confidence_type = 'highest_prob' #Hyperparameter\n",
    "\n",
    "    # Class balance between the 4 classes. \n",
    "    #This is a formality, as the dataset is balanced, with equal number epochs for each of the 4 classes.\n",
    "    class_balance = np.zeros(4)\n",
    "    for i in range(4):\n",
    "        class_balance[i] = np.mean(labels == i)\n",
    "\n",
    "    class_balance = np.max(class_balance)\n",
    "\n",
    "    class_names = {\n",
    "            1: \"Left hand\",\n",
    "            2: \"Right hand\",\n",
    "            3: \"Both feet\",\n",
    "            4: \"Tongue\"\n",
    "    }\n",
    "\n",
    "    sfreq = 250 # Sampling frequency of 250 Hz as per the BCI competion dataset 2a\n",
    "\n",
    "    # Classify the signal using a sliding window\n",
    "    w_length = int(sfreq * 0.5)  # Window length - Hyperparameter.\n",
    "    w_step = int(sfreq * 0.5)  # window step size - Hyperparameter.\n",
    "\n",
    "    #if w_length = sfreq * 0.5 and w_step = sfreq * 0.1. Theres 36 starting points\n",
    "    # Set of starting positions in the signal(Note! the signal is 2s to 4s) \n",
    "    w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step) \n",
    "    scores_cv_splits = [] \n",
    "    predict_time_cv_splits = []\n",
    "    confidence_cv_split = []\n",
    "    # Running classification across the signal\n",
    "    for train_idx, test_idx in cv_split:\n",
    "        currentcv+=1\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx] # Get the current labels and data\n",
    "\n",
    "        # Exatract spatial filters and transform the data \n",
    "        X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "        X_test = csp.transform(epochs_data_train[test_idx]) #  why define and transform it here, and then do it later as well!\n",
    "\n",
    "        # Fit the classifier on the training data\n",
    "        lda.fit(X_train, y_train)\n",
    "        w_times = (w_start + w_length / 2.0) / sfreq + epochs.tmin\n",
    "        scores_across_epochs = []\n",
    "        confidences_across_epochs = []\n",
    "        predict_time_across_epochs = []\n",
    "        current_epoch = 0     \n",
    "        #The testset is 20% 116 epochs of the whole data 576 epochs(trials) for each subject\n",
    "        for epoch_idx in range(len(test_idx)):  #for each epoch\n",
    "            current_n = 0\n",
    "            predict_time = 0\n",
    "            current_epoch+=1\n",
    "            predict = False \n",
    "            current_window = 0\n",
    "            numTimesBelowThreshold = 0\n",
    "            confidences_across_windows =[]\n",
    "            for n in w_start: #for each sliding window\n",
    "                current_window +=1 \n",
    "                print(f\" Subject {current_person} CV {currentcv}, epoch: {current_epoch}, and window:{current_window}\")\n",
    "\n",
    "                X_test_window = csp.transform(epochs_data[test_idx][:, :, n:(n + w_length)])\n",
    "                X_test_epoch_window = X_test_window[epoch_idx]\n",
    "\n",
    "                #Early prediction\n",
    "                probabilities = lda.predict_proba([X_test_epoch_window])\n",
    "                probabilities = np.array(probabilities)\n",
    "                probabilities = probabilities.flatten()\n",
    "\n",
    "                # predict becomes true to predict early then go to the next epoch\n",
    "                predict, confidence, numTimesBelowThreshold = early_pred(probabilities, predict, numTimesBelowThreshold, patience, confidence_type)\n",
    "                confidences_across_windows.append(confidence)\n",
    "                if predict:\n",
    "                    predict_time = n\n",
    "                    print(\"early prediction\")\n",
    "                    score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                    break # predicting early\n",
    "                current_n+=1\n",
    "            else:\n",
    "                predict_time = n #if not predicted early, we still predict as we have reached the end of the signal \n",
    "                score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                print(\"no early prediction in this epoch, numTimesBelowThreshold:\", numTimesBelowThreshold)\n",
    "            predict_time = (predict_time + w_length / 2.0) / sfreq + epochs.tmin\n",
    "            scores_across_epochs.append(score)\n",
    "            predict_time_across_epochs.append(predict_time)\n",
    "    \n",
    "        if currentcv == 1:\n",
    "            scores_cv_splits = np.array(scores_across_epochs)\n",
    "            predict_time_cv_splits = np.array(predict_time_across_epochs)\n",
    "        else:\n",
    "            scores_cv_splits = np.vstack((scores_cv_splits,np.array(scores_across_epochs)))\n",
    "            predict_time_cv_splits = np.vstack((predict_time_cv_splits,np.array(predict_time_across_epochs)))\n",
    "\n",
    "    mean_scores_across_cv = np.mean(scores_cv_splits, axis=0)\n",
    "    mean_predict_time_across_cv = np.mean(predict_time_cv_splits, axis=0)\n",
    "    if person == 1:\n",
    "        scores_across_subjects  = np.array(mean_scores_across_cv)\n",
    "        prediction_time_across_subjects = np.array(mean_predict_time_across_cv)\n",
    "    else:\n",
    "        scores_across_subjects = np.vstack((scores_across_subjects,np.array(mean_scores_across_cv)))\n",
    "        prediction_time_across_subjects = np.vstack((predict_time_cv_splits,np.array(mean_predict_time_across_cv)))\n",
    "\n",
    "mean_scores_across_subjects = np.mean(scores_across_subjects, axis=0)\n",
    "accuracy = np.mean(mean_scores_across_subjects)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (accuracy, class_balance))\n",
    "mean_prediction_time_across_subjects = np.mean(prediction_time_across_subjects, axis=0)\n",
    "mean_prediction_time = np.mean(mean_prediction_time_across_subjects) -2\n",
    "max_time = epochs.tmax-2\n",
    "print(\"Mean prediction time: %f / full time: %f /  Percentage of time: %f\" % (mean_prediction_time, max_time, mean_prediction_time/max_time))\n",
    "\n",
    "''''\n",
    "plt.plot(len(test_idx), mean_scores_across_cv, label=\"Score\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.axvline(2, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "plt.axhline(class_balance, linestyle=\"-\", color=\"k\", label=\"Chance\")\n",
    "plt.title(\"Classification accuracy over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "#print(\"scores_cv_splits (10X116?) shape:\",scores_across_epochs\n",
    "#print(\"predict_time_cv_splits (10X116?) shape: \", predict_time_across_epochs).shape\n",
    "\n",
    "'''\n",
    "To do - dynamic stop:\n",
    "- sliding\n",
    "    - make the for loops work and contain and provide the mean predict time and score correctly X\n",
    "    - then advance to for all subjects X\n",
    "    - modularize\n",
    "    - the start the hyperparameter tuning to maximize classification accuracy, and minimize predict_time \n",
    "    - then loop across all threshold values \n",
    "    - make it take into account all the subjects\n",
    "    - make it work using svm\n",
    "    - provide the plots for all the subjects for all subjects for each condition, let it just save the plots to a folder automatically (potentially also the values to make plots somewhere else)\n",
    "    - nb: watch the memory and time usage for codespaces\n",
    "- expanding:\n",
    "    - make a new file, adjust to use expanding window\n",
    "    - save its plots into another folder automaically\n",
    "            \n",
    "To do - static:\n",
    "- make a new file and adjust the dynamic to just use a specific predict times using the cost function\n",
    "- save the plots\n",
    "\n",
    "to do - whole:\n",
    "- already did that lol\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print(\"len w-times: \", w_times)\n",
    "print(\"len w-start: \", w_start)\n",
    "print(\"len w-times[:numberOfNs]: \", w_times[:numberOfNs])\n",
    "print(\"len w-start[:numberOfNs]: \", w_start[:numberOfNs])\n",
    "print(\"number n's \", numberOfNs)\n",
    "'''\n",
    "\n",
    "''' ##Costs for each of the classes for each window\n",
    "plt.plot(w_times, confidences, label='Cost')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.axvline(w_times[predict_time], linestyle=\"-\", color=\"b\", label=\"Stopping\")\n",
    "plt.axvline(2, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "plt.axhline(0.5, linestyle=\"-\", color=\"k\", label=\"Threshold\")\n",
    "plt.title(\"Cost over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##Accuracy for each window\n",
    "plt.plot(w_times, score_this_window, label=\"Score\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.axvline(w_times[predict_time], linestyle=\"-\", color=\"b\", label=\"Stopping\")\n",
    "plt.axvline(2, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "plt.axhline(class_balance, linestyle=\"-\", color=\"k\", label=\"Chance\")\n",
    "plt.title(\"Classification accuracy over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(w_times, confidence_this_window, label=\"Score\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Confidence\")\n",
    "plt.ylim(0,1)\n",
    "plt.axvline(w_times[predict_time], linestyle=\"-\", color=\"b\", label=\"Stopping\")\n",
    "plt.axvline(2, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "#plt.axhline(threshold, linestyle=\"-\", color=\"k\", label=\"Threshold\")\n",
    "plt.title(\"Model confindence over Time\")\n",
    "plt.legend()\n",
    "plt.show()'''\n",
    "\n",
    "'''\n",
    "        \n",
    "    #sanity check\n",
    "    for epoch_idx in range(len(test_idx)): \n",
    "        current_n = 0\n",
    "        current_epoch+=1\n",
    "        predict = False \n",
    "        numTimesBelowThreshold = 0\n",
    "        confidences_across_windows_full =[]\n",
    "        probs_across_windows = []\n",
    "        ##Earl pred\n",
    "        for n in w_start:\n",
    "            X_test_window = csp.transform(epochs_data[test_idx][:, :, n:(n + w_length)])\n",
    "            X_test_epoch_window = X_test_window[epoch_idx+1]\n",
    "\n",
    "            #Early prediction\n",
    "            probabilities = lda.predict_proba([X_test_epoch_window])\n",
    "\n",
    "            if len(probs_across_windows) == 0:\n",
    "               probs_across_windows = probabilities\n",
    "            else:\n",
    "                probs_across_windows = np.vstack((probs_across_windows, probabilities))\n",
    "\n",
    "            probabilities = np.array(probabilities)\n",
    "            probabilities = probabilities.flatten()\n",
    "            # predict becomes true to predict ealrly then go to the next epoch\n",
    "            predict, confidence, numTimesBelowThreshold= early_pred(probabilities, predict, numTimesBelowThreshold, patience)\n",
    "            confidences_across_windows_full.append(confidence)\n",
    "            score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx+1]])\n",
    "        plt.plot(w_times, confidences_across_windows_full, label='confidences_across_windows_full')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"confidence\")\n",
    "        plt.axvline(predict_time, linestyle=\"-\", color=\"b\", label=\"Stopping\")\n",
    "        plt.axvline(2, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "        plt.axhline(0.5, linestyle=\"-\", color=\"k\", label=\"Threshold\")\n",
    "        plt.title(\"Cost over Time\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        y_test = y_test+4\n",
    "        print(\"right label:\", class_names[y_test[epoch_idx+1]])\n",
    "            ##Probabiltiies for each of the classes for each window\n",
    "        plt.plot(w_times, probs_across_windows, label=[class_names[label] for label in [1, 2, 3, 4]])\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Probabilities\")\n",
    "        plt.axvline(predict_time, linestyle=\"-\", color=\"b\", label=\"Stopping\")\n",
    "        plt.axvline(2, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "        plt.axhline(0.5, linestyle=\"-\", color=\"k\", label=\"Threshold\")\n",
    "        plt.title(\"Classification probabilities over Time\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
