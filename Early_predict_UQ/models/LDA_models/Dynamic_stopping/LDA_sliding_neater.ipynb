{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from mne.decoding import CSP\n",
    "\n",
    "current_directory = os.path.abspath('')\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(current_directory, '..', '..', '..', '..'))\n",
    "\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"ROOT:\", project_root)\n",
    "from Early_predict_UQ.data.make_dataset import make_data\n",
    "\n",
    "\n",
    "\n",
    "def early_pred(probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold):\n",
    "    probabilities = probabilities.flatten()\n",
    "    sorted_probs = sorted(probabilities, reverse=True)\n",
    "    if confidence_type == 'highest_prob':\n",
    "        confidence = sorted_probs[0]\n",
    "    else:\n",
    "        confidence = 1 - (1 / (1 + (sorted_probs[0] + (sorted_probs[0] - sorted_probs[1]))))\n",
    "    if confidence > threshold and not predict:\n",
    "        print(\"confindence:\", confidence)\n",
    "        sorted_probs[0]\n",
    "        numTimesBelowThreshold += 1\n",
    "        if numTimesBelowThreshold == patience:\n",
    "            predict = True\n",
    "    return predict, confidence, numTimesBelowThreshold\n",
    "\n",
    "def run_sliding_classification(subjects, threshold, patience, confidence_type, w_length, w_step, sfreq):\n",
    "    scores_across_subjects = []\n",
    "    prediction_time_across_subjects = []\n",
    "    current_person = 0\n",
    "    for person in subjects:\n",
    "        current_person += 1\n",
    "        print(\"Person %d\" % (person))\n",
    "        subject= [person]\n",
    "        epochs, labels = make_data(subject)\n",
    "        epochs_train = epochs.copy()\n",
    "        labels = epochs.events[:, -1] - 4\n",
    "        epochs_data = epochs.get_data(copy=False)\n",
    "        epochs_data_train = epochs_train.get_data(copy=False)\n",
    "\n",
    "        cv = ShuffleSplit(2, test_size=0.2, random_state=42)\n",
    "        cv_split = cv.split(epochs_data_train)\n",
    "        scores_cv_splits = []\n",
    "        predict_time_cv_splits = []\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        csp = CSP(n_components=5, reg=None, log=True, norm_trace=False)\n",
    "        current_cv = 0 \n",
    "        for train_idx, test_idx in cv_split:\n",
    "            current_cv += 1\n",
    "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "            X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "            lda.fit(X_train, y_train)\n",
    "            w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step) \n",
    "            scores_across_epochs = []\n",
    "            predict_time_across_epochs = []\n",
    "\n",
    "            for epoch_idx in range(len(test_idx)):\n",
    "                predict = False\n",
    "                numTimesBelowThreshold = 0\n",
    "                for n in w_start:\n",
    "                    X_test_window = csp.transform(epochs_data_train[test_idx][:, :, n:(n + w_length)])\n",
    "                    X_test_epoch_window = X_test_window[epoch_idx]\n",
    "                    probabilities = lda.predict_proba([X_test_epoch_window])\n",
    "                    probabilities = np.array(probabilities)\n",
    "                    probabilities = probabilities.flatten()\n",
    "                    predict, confidence, numTimesBelowThreshold = early_pred(\n",
    "                        probabilities, predict, numTimesBelowThreshold, patience, confidence_type, threshold\n",
    "                    )\n",
    "                    if predict:\n",
    "                        #IF WE DIDNT PREDICT EARLY, MAYBE PREDICT ON THE WHOLE EPOCH?\n",
    "                        predict_time = n\n",
    "                        score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                        break\n",
    "                else:\n",
    "                    predict_time = n\n",
    "                    score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                predict_time = (predict_time + w_length / 2.0) / sfreq + epochs.tmin\n",
    "                scores_across_epochs.append(score)\n",
    "                predict_time_across_epochs.append(predict_time)\n",
    "\n",
    "            if current_cv == 1:\n",
    "                scores_cv_splits = np.array(scores_across_epochs)\n",
    "                predict_time_cv_splits = np.array(predict_time_across_epochs)\n",
    "            else:\n",
    "                scores_cv_splits = np.vstack((scores_cv_splits,np.array(scores_across_epochs)))\n",
    "                predict_time_cv_splits = np.vstack((predict_time_cv_splits,np.array(predict_time_across_epochs)))\n",
    "\n",
    "        mean_scores_across_cv = np.mean(scores_cv_splits, axis=0)\n",
    "        mean_predict_time_across_cv = np.mean(predict_time_cv_splits, axis=0)\n",
    "        if current_person == 1:\n",
    "            scores_across_subjects  = np.array(mean_scores_across_cv)\n",
    "            prediction_time_across_subjects = np.array(mean_predict_time_across_cv)\n",
    "        else:\n",
    "            scores_across_subjects = np.vstack((scores_across_subjects,np.array(mean_scores_across_cv)))\n",
    "            prediction_time_across_subjects = np.vstack((predict_time_cv_splits,np.array(mean_predict_time_across_cv)))\n",
    "\n",
    "        mean_scores_across_subjects = np.mean(scores_across_subjects, axis=0)\n",
    "        accuracy = np.mean(mean_scores_across_subjects)\n",
    "\n",
    "        mean_prediction_time_across_subjects = np.mean(prediction_time_across_subjects, axis=0)\n",
    "        mean_prediction_time = np.mean(mean_prediction_time_across_subjects)\n",
    "    return accuracy, mean_prediction_time, epochs, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #threshold = 0.6  # values - {0,1}\n",
    "    #patience = 4 # values - {1,36}\n",
    "    subjects = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "    confidence_type = 'highest_prob' # 'highest_prob' or the cost function. # hyperparameter - maybe compare in different files\n",
    "    sfreq = 250      \n",
    "    w_length = int(sfreq * 0.5)  \n",
    "    w_step = int(sfreq * 0.5)   \n",
    "\n",
    "    #csp components #hyperparameter\n",
    "    #cross validation #hyperparmater\n",
    "accuracy_array = []\n",
    "prediction_time_array = []\n",
    "\n",
    "#MIGHT BE TOO INTENSIVE FOR THE KERNEL, maybe tune the other hyperparameters first, then with the best values, loop over patience, and trehsold\n",
    "# over threshold values\n",
    "for threshold in np.arange(0, 1, 0.2):\n",
    "    accuracy_row = []\n",
    "    prediction_time_row = []\n",
    "    # over patience values\n",
    "    for patience in np.arange(1, 36, 4):\n",
    "        accuracy, mean_prediction_time, epochs, labels = run_sliding_classification(subjects, threshold, patience, confidence_type, w_length, w_step, sfreq)\n",
    "        accuracy_row.append(accuracy)\n",
    "        prediction_time_row.append(mean_prediction_time)\n",
    "    accuracy_array.append(accuracy_row)\n",
    "    prediction_time_array.append(prediction_time_row)\n",
    "\n",
    "accuracy_array = np.array(accuracy_array)\n",
    "prediction_time_array = np.array(prediction_time_array)\n",
    "\n",
    "print(\"accuracy_array: \", accuracy_array)\n",
    "print(\"prediction_time_array: \",  prediction_time_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Plotting and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "accuracy_array = np.array(accuracy_array)\n",
    "prediction_time_array = np.array(prediction_time_array)\n",
    "\n",
    "accuracy_df = pd.DataFrame(accuracy_array, \n",
    "                           index=np.arange(0, 1, 0.2),\n",
    "                           columns=np.arange(1, 36, 4))\n",
    "\n",
    "prediction_time_df = pd.DataFrame(prediction_time_array, \n",
    "                                  index=np.arange(0, 1, 0.2),\n",
    "                                  columns=np.arange(1, 36, 4))\n",
    "\n",
    "# Plotting accuracy\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.plot_surface(accuracy_df.columns, accuracy_df.index, accuracy_df.values, cmap='viridis')\n",
    "ax.set_xlabel('Patience')\n",
    "ax.set_ylabel('Threshold')\n",
    "ax.set_zlabel('Accuracy')\n",
    "ax.set_title('Accuracy vs Threshold and Patience')\n",
    "\n",
    "# Plotting prediction time\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.plot_surface(prediction_time_df.columns, prediction_time_df.index, prediction_time_df.values, cmap='viridis')\n",
    "ax.set_xlabel('Patience')\n",
    "ax.set_ylabel('Threshold')\n",
    "ax.set_zlabel('Prediction Time')\n",
    "ax.set_title('Prediction Time vs Threshold and Patience')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A formality as classes are balanced\n",
    "class_balance = np.zeros(4)\n",
    "for i in range(4):\n",
    "    class_balance[i] = np.mean(labels == i)\n",
    "class_balance = np.max(class_balance)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 1, 0.2), accuracy_across_threshold_values, label=\"Accuracy\")\n",
    "#plt.axvline(2, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "#plt.axvline(w_times[predict_time], linestyle=\"-\", color=\"k\", label=\"Stopping\")\n",
    "plt.axhline(class_balance, linestyle=\"-\", color=\"k\", label=\"Chance\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.title(\"Classification score accross threshold values\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(accuracy_across_threshold_values), class_balance))\n",
    "\n",
    "#Subtracting time before the cue at 2s\n",
    "mean_prediction_time -= 2\n",
    "max_time = epochs.tmax - 2\n",
    "print(\"Mean prediction time: %f / Full time: %f / Percentage of time: %f\" % (np.mean(mean_prediction_time_across_threshold_values), max_time,np.mean(mean_prediction_time_across_threshold_values) / max_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
