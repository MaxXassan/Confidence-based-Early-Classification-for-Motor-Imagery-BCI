{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> LDA with static stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from mne.decoding import CSP\n",
    "\n",
    "current_directory = os.path.abspath('')\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(current_directory, '..', '..', '..', '..'))\n",
    "\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"ROOT:\", project_root)\n",
    "from Early_predict_UQ.data.make_dataset import make_data\n",
    "\n",
    "# epoch tmin  = 2 and tmax = 6 , as the motor imagery task lasted in that time\n",
    "\n",
    "def run_expanding_classification(subjects, initial_window_length, expansion_rate, sfreq,  prediction_time):\n",
    "    scores_across_subjects = []\n",
    "    current_person = 0\n",
    "    for person in subjects:\n",
    "        current_person += 1\n",
    "        print(\"Person %d\" % (person))\n",
    "        subject= [person]\n",
    "        epochs, labels = make_data(subject)\n",
    "        epochs_train = epochs.copy()\n",
    "        labels = epochs.events[:, -1] - 4\n",
    "        epochs_data = epochs.get_data(copy=False)\n",
    "        epochs_data_train = epochs_train.get_data(copy=False)\n",
    "\n",
    "        cv = ShuffleSplit(2, test_size=0.2, random_state=42)\n",
    "        cv_split = cv.split(epochs_data_train)\n",
    "        scores_cv_splits = []\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "        current_cv = 0 \n",
    "        for train_idx, test_idx in cv_split:\n",
    "            current_cv += 1\n",
    "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "            X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "            lda.fit(X_train, y_train)\n",
    "            w_start = np.arange(0, epochs_data.shape[2] - initial_window_length, expansion_rate) \n",
    "            scores_across_epochs = []\n",
    "            for epoch_idx in range(len(test_idx)):\n",
    "                for n, window_start in enumerate(w_start):\n",
    "                    window_length = initial_window_length + n * expansion_rate\n",
    "                    X_test_window = csp.transform(epochs_data_train[test_idx][:, :,  window_start:(window_start + window_length)])\n",
    "                    X_test_epoch_window = X_test_window[epoch_idx]\n",
    "                    print(\"window_start:\", window_start)\n",
    "                    print(\"prediction_time:\", prediction_time)\n",
    "                    if window_start == prediction_time:\n",
    "                        score = lda.score(X_test_epoch_window.reshape(1, -1), [y_test[epoch_idx]])\n",
    "                        scores_across_epochs.append(score)\n",
    "                        break\n",
    "            if current_cv == 1:\n",
    "                scores_cv_splits = np.array(scores_across_epochs)\n",
    "            else:\n",
    "                scores_cv_splits = np.vstack((scores_cv_splits,np.array(scores_across_epochs)))\n",
    "\n",
    "        mean_scores_across_cv = np.mean(scores_cv_splits, axis=0)\n",
    "        if current_person == 1:\n",
    "            scores_across_subjects  = np.array(mean_scores_across_cv)\n",
    "        else:\n",
    "            scores_across_subjects = np.vstack((scores_across_subjects,np.array(mean_scores_across_cv)))\n",
    "\n",
    "        mean_scores_across_subjects = np.mean(scores_across_subjects, axis=0)\n",
    "        accuracy = np.mean(mean_scores_across_subjects)\n",
    "    return accuracy, epochs, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    subjects = [1, 2, 3, 4, 5, 6, 7, 8, 9]  # 9 subjects\n",
    "    sfreq = 250      \n",
    "\n",
    "    initial_window_length = int(sfreq * 0.5)  \n",
    "    expansion_rate = int(sfreq * 0.1)   \n",
    "\n",
    "    epochs, labels = make_data([1]) # just to access the epoch.shape\n",
    "    epochs_data = epochs.get_data(copy=False)\n",
    "    prediction_times = np.arange(0, epochs_data.shape[2] - initial_window_length, expansion_rate)\n",
    "\n",
    "    accuracy_array = []\n",
    "\n",
    "    #something like this\n",
    "    print(\"accuracy_array: \", accuracy_array)\n",
    "    print(\" prediction_times: \",  prediction_times)\n",
    "    for current_pred_time, prediction_time in enumerate(prediction_times):\n",
    "        print(f\"prediction_time: {current_pred_time + 1} / {len(prediction_times)}\")\n",
    "        accuracy, epochs, labels = run_expanding_classification(subjects, initial_window_length, expansion_rate, sfreq, prediction_time)\n",
    "        accuracy_array.append(accuracy)\n",
    "\n",
    "    accuracy_array = np.array(accuracy_array)\n",
    "    print(\"accuracy_array: \", accuracy_array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
